from tokenizers import ByteLevelBPETokenizer
from pathlib import Path
import os
import argparse

import json

# 提取函数并写入txt文件
with open('20200621_Python_function_docstring_datasets_train.json', 'r') as json_file, \
        open('functions.txt', 'w') as txt_file:
    for line in json_file:
        data = json.loads(line)
        function = data['function']
        txt_file.write(function + '\n')


def bbpe(vocab_size):
    bbpeTokenizer = ByteLevelBPETokenizer()
    bbpeTokenizer.train(files='functions.txt', vocab_size=vocab_size, min_frequency=2, special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])
    os.mkdir(f'./BBPE_{int(vocab_size/1000)}k')
    bbpeTokenizer.save_model(f'./BBPE_{int(vocab_size/1000)}k')


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--tokenizer', type=str, default='bbpe')
    parser.add_argument('--vocab_size', type=int, default=30)
    args = parser.parse_args()
    bbpe(1000*args.vocab_size)


if __name__ == '__main__':
    main()
